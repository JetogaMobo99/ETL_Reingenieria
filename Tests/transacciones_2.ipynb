{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Ejecutando consulta en HANA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmarquez\\AppData\\Local\\Temp\\ipykernel_10868\\2011536117.py:75: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_transacciones = pd.read_sql(query_hana, conn_hana)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Registros obtenidos: 124163\n",
      "üìÅ Archivo exportado a CSV: C:\\Users\\jmarquez\\Documents\\ventas_desde_20250614_hasta_20250624.csv\n",
      "üßπ Registros eliminados de stage_ventas_devo.\n",
      "üìÑ Leyendo archivo CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmarquez\\AppData\\Local\\Temp\\ipykernel_10868\\2011536117.py:103: DtypeWarning: Columns (2,5,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta_completa, encoding='utf-8-sig')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Se encontraron registros con fechas nulas en 'fecha_venta' o 'fecha_proc'.\n",
      "Archivo con registros inv√°lidos: C:\\Users\\jmarquez\\Documents\\errores_fechas_nulas_20250624.csv\n",
      "üìß Correo enviado.\n",
      "üñ•Ô∏è Conectando a SQL Server...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import pyodbc\n",
    "from hdbcli import dbapi\n",
    "import os\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "import csv\n",
    "\n",
    "# --------------------------------------------\n",
    "# PAR√ÅMETROS DE CORREO (SENDGRID)\n",
    "# --------------------------------------------\n",
    "SERVER_HOST_MAIL = \"smtp.sendgrid.net\"\n",
    "SERVER_PORT_MAIL = 587\n",
    "SERVER_USER_MAIL = \"apikey\"\n",
    "SERVER_FROM_MAIL = \"no-reply@mobonet.mx\"\n",
    "DESTINATARIOS = [\"jmarquez@mobo.com.mx\"]\n",
    "\n",
    "def enviar_correo(asunto, cuerpo):\n",
    "    msg = EmailMessage()\n",
    "    msg[\"Subject\"] = asunto\n",
    "    msg[\"From\"] = SERVER_FROM_MAIL\n",
    "    msg[\"To\"] = \", \".join(DESTINATARIOS)\n",
    "    msg.set_content(cuerpo)\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP(SERVER_HOST_MAIL, SERVER_PORT_MAIL) as smtp:\n",
    "            smtp.starttls()\n",
    "            smtp.login(SERVER_USER_MAIL, SERVER_PASS_MAIL)\n",
    "            smtp.send_message(msg)\n",
    "        print(\"üìß Correo enviado.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error al enviar el correo:\", e)\n",
    "\n",
    "# --------------------------------------------\n",
    "# CONEXIONES\n",
    "# --------------------------------------------\n",
    "conn_hana = dbapi.connect(\n",
    "    address=\"192.168.10.13\",\n",
    "    port=30015,\n",
    "    user=\"bimobo\",\n",
    "    password=\"\"\n",
    ")\n",
    "\n",
    "conn_sql = pyodbc.connect(\n",
    "    'DRIVER={SQL Server};SERVER=SRVSQLBIDEV\\\\SQLSERVERDEV;DATABASE=MOBODW_STG;UID=SA;PWD='\n",
    ")\n",
    "cursor_sql = conn_sql.cursor()\n",
    "\n",
    "# --------------------------------------------\n",
    "# FECHAS Y RUTA ARCHIVO\n",
    "# --------------------------------------------\n",
    "ayer = date.today() - timedelta(days=1)\n",
    "fecha_ayer = int(ayer.strftime('%Y%m%d'))\n",
    "fecha_10 = ayer - timedelta(days=10)\n",
    "fecha_inicio = int(fecha_10.strftime('%Y%m%d'))\n",
    "\n",
    "fecha_ayer_sql = ayer.strftime('%Y-%m-%d')\n",
    "fecha_10_sql = (ayer - timedelta(days=10)).strftime('%Y-%m-%d')\n",
    "\n",
    "ruta_destino = r\"C:\\Users\\jmarquez\\Documents\"\n",
    "nombre_archivo = f\"ventas_desde_{fecha_inicio}_hasta_{fecha_ayer}.csv\"\n",
    "ruta_completa = os.path.join(ruta_destino, nombre_archivo)\n",
    "\n",
    "# --------------------------------------------\n",
    "# EXTRACCI√ìN DESDE HANA\n",
    "# --------------------------------------------\n",
    "query_hana = f\"\"\"\n",
    "CALL \"MOBO_PRODUCTIVO\".\"SYS_RP_FCT_VENTAS_COPY2\" ('{fecha_inicio}', '{fecha_ayer}')\n",
    "\"\"\"\n",
    "print(\"üì° Ejecutando consulta en HANA...\")\n",
    "\n",
    "try:\n",
    "    df_transacciones = pd.read_sql(query_hana, conn_hana)\n",
    "    print(f\"üì• Registros obtenidos: {len(df_transacciones)}\")\n",
    "\n",
    "    if not df_transacciones.empty:\n",
    "        df_transacciones.to_csv(ruta_completa, index=False)\n",
    "        print(f\"üìÅ Archivo exportado a CSV: {ruta_completa}\")\n",
    "\n",
    "        delete_query = f\"\"\"\n",
    "        DELETE FROM stage_ventas_devo\n",
    "        WHERE cast(fecha_venta as date) BETWEEN '{fecha_10_sql}' AND '{fecha_ayer_sql}'\n",
    "        \"\"\"\n",
    "        cursor_sql.execute(delete_query)\n",
    "        conn_sql.commit()\n",
    "        print(\"üßπ Registros eliminados de stage_ventas_devo.\")\n",
    "    else:\n",
    "        raise ValueError(\"La consulta no devolvi√≥ ning√∫n dato. No se exporta CSV ni se elimina tabla.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error durante el proceso:\", e)\n",
    "    enviar_correo(\n",
    "        asunto=\"‚ùå Error en exportaci√≥n o eliminaci√≥n de registros\",\n",
    "        cuerpo=f\"Ocurri√≥ un error durante la ejecuci√≥n del script:\\n\\n{e}\"\n",
    "    )\n",
    "\n",
    "# --------------------------------------------\n",
    "# CARGA A SQL SERVER DESDE CSV\n",
    "# --------------------------------------------\n",
    "print(\"üìÑ Leyendo archivo CSV...\")\n",
    "df = pd.read_csv(ruta_completa, encoding='utf-8-sig')\n",
    "\n",
    "columnas_sql = [\n",
    "    'venta_id', 'fecha_venta', 'fecha_proc', 'sucursal', 'hora_venta',\n",
    "    'folio_venta', 'referencia', 'cliente_id', 'caja', 'agente_ventas',\n",
    "    'subtotal', 'total_neto', 'tipo_transaccion', 'almacen', 'num_linea',\n",
    "    'sku', 'cantidad', 'precio_bruto_c_dcto', 'impuesto', 'descuento',\n",
    "    'precio_neto_c_dcto', 'importe_c_dcto', 'dcto_por_cupon', 'codigo_promo',\n",
    "    'porc_descuento_nm', 'cant_gratis_nm', 'origen', 'tipo_documento', 'tipo',\n",
    "    'hora_round', 'cupon_gen', 'cupon_red', 'estatus_sku'\n",
    "]\n",
    "\n",
    "columnas_numericas = [\n",
    "    'subtotal', 'total_neto', 'cantidad', 'precio_bruto_c_dcto',\n",
    "    'impuesto', 'descuento', 'precio_neto_c_dcto', 'importe_c_dcto',\n",
    "    'dcto_por_cupon', 'porc_descuento_nm', 'cant_gratis_nm'\n",
    "]\n",
    "\n",
    "columnas_fecha = ['fecha_venta', 'fecha_proc']\n",
    "\n",
    "# Agregar columnas faltantes\n",
    "for col in ['venta_id', 'hora_round', 'estatus_sku']:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "df.rename(columns={\n",
    "    'conf_cupon_gen': 'cupon_gen',\n",
    "    'conf_cupon_red': 'cupon_red'\n",
    "}, inplace=True)\n",
    "\n",
    "# Relleno y limpieza\n",
    "df['cupon_gen'] = df['cupon_gen'].fillna('')\n",
    "df['cupon_red'] = df['cupon_red'].fillna('')\n",
    "\n",
    "for col in columnas_numericas:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "columnas_texto = [\n",
    "    col for col in columnas_sql\n",
    "    if col not in columnas_numericas + columnas_fecha + ['venta_id', 'hora_round', 'estatus_sku']\n",
    "]\n",
    "for col in columnas_texto:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('')\n",
    "\n",
    "for col in columnas_fecha:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    df[col] = df[col].where(pd.notnull(df[col]), None)\n",
    "\n",
    "for col in ['venta_id', 'hora_round', 'estatus_sku']:\n",
    "    df[col] = df[col].where(pd.notnull(df[col]), None)\n",
    "\n",
    "df.replace('', None, inplace=True)\n",
    "df = df.where(pd.notnull(df), None)\n",
    "df = df[columnas_sql]\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# LIMPIEZA Y TRANSFORMACI√ìN DE FECHAS\n",
    "# --------------------------------------------\n",
    "for col in columnas_fecha:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')  # convierte strings vac√≠os en NaT\n",
    "    df[col] = df[col].astype(object)  # convertir a object para poder tener None\n",
    "    df[col] = df[col].where(df[col].notnull(), None)  # reemplaza NaT con None\n",
    "\n",
    "# Validaci√≥n adicional: reportar si existen fechas nulas antes de insertar\n",
    "if df['fecha_venta'].isnull().any() or df['fecha_proc'].isnull().any():\n",
    "    errores_fecha = df[df['fecha_venta'].isnull() | df['fecha_proc'].isnull()]\n",
    "    archivo_fechas_nulas = os.path.join(ruta_destino, f\"errores_fechas_nulas_{fecha_ayer}.csv\")\n",
    "    errores_fecha.to_csv(archivo_fechas_nulas, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    mensaje_error = (\n",
    "        f\"‚ùå Se encontraron registros con fechas nulas en 'fecha_venta' o 'fecha_proc'.\\n\"\n",
    "        f\"Archivo con registros inv√°lidos: {archivo_fechas_nulas}\"\n",
    "    )\n",
    "    print(mensaje_error)\n",
    "    \n",
    "    enviar_correo(\n",
    "        asunto=\"‚ùå Error: Fechas nulas detectadas en archivo de ventas\",\n",
    "        cuerpo=mensaje_error\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# INSERCI√ìN POR BLOQUES CON LOG DE ERRORES\n",
    "# --------------------------------------------\n",
    "print(\"üñ•Ô∏è Conectando a SQL Server...\")\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={SQL Server};SERVER=SRVSQLBIDEV\\\\SQLSERVERDEV;DATABASE=MOBODW_STG;UID=SA;PWD=BISAP_Mobo@DA2020'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_query = f\"\"\"\n",
    "INSERT INTO stage_ventas_devo ({', '.join(['[' + col + ']' for col in columnas_sql])})\n",
    "VALUES ({', '.join(['?'] * len(columnas_sql))})\n",
    "\"\"\"\n",
    "\n",
    "insertados = 0\n",
    "errores = 0\n",
    "chunk_size = 100000\n",
    "total = len(df)\n",
    "\n",
    "archivo_errores = os.path.join(ruta_destino, f\"errores_insercion_{fecha_ayer}.csv\")\n",
    "errores_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8dbade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error al insertar registros de la fila 0 a 100000: \n"
     ]
    }
   ],
   "source": [
    "cursor.fast_executemany = True\n",
    "for start in range(0, total, chunk_size):\n",
    "    end = min(start + chunk_size, total)\n",
    "    chunk = df.iloc[start:end]\n",
    "    data_chunk = [tuple(row) for _, row in chunk.iterrows()]     \n",
    "    try:\n",
    "        cursor.executemany(insert_query, data_chunk)\n",
    "        conn.commit()\n",
    "        insertados += len(data_chunk)\n",
    "        print(f\"‚úÖ Registros insertados de la fila {start} a {end}: {len(data_chunk)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al insertar registros de la fila {start} a {end}: {e}\")\n",
    "        errores += len(data_chunk)\n",
    "        for index, row in chunk.iterrows():\n",
    "            try:\n",
    "                cursor.execute(insert_query, tuple(row))\n",
    "            except Exception as e:\n",
    "                errores_list.append({\n",
    "                    'index': index,\n",
    "                    'error': str(e),\n",
    "                    **row.to_dict()\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"üöÄ Iniciando inserci√≥n de {total} registros...\")\n",
    "for start in range(0, total, chunk_size):\n",
    "    end = min(start + chunk_size, total)\n",
    "    chunk = df.iloc[start:end]\n",
    "    for idx, row in chunk.iterrows():\n",
    "        try:\n",
    "            cursor.execute(insert_query, tuple(row[col] for col in columnas_sql))\n",
    "            insertados += 1\n",
    "        except Exception as e:\n",
    "            errores += 1\n",
    "            errores_list.append({**row.to_dict(), 'error': str(e)})\n",
    "    conn.commit()\n",
    "    print(f\"‚úÖ {insertados} registros insertados (hasta la fila {end})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"üöÄ Iniciando inserci√≥n de {total} registros...\")\n",
    "for start in range(0, total, chunk_size):\n",
    "    end = min(start + chunk_size, total)\n",
    "    chunk = df.iloc[start:end]\n",
    "    for idx, row in chunk.iterrows():\n",
    "        try:\n",
    "            cursor.execute(insert_query, tuple(row[col] for col in columnas_sql))\n",
    "            insertados += 1\n",
    "        except Exception as e:\n",
    "            errores += 1\n",
    "            errores_list.append({**row.to_dict(), 'error': str(e)})\n",
    "    conn.commit()\n",
    "    print(f\"‚úÖ {insertados} registros insertados (hasta la fila {end})\")\n",
    "\n",
    "if errores_list:\n",
    "    keys = errores_list[0].keys()\n",
    "    with open(archivo_errores, 'w', newline='', encoding='utf-8-sig') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(errores_list)\n",
    "    print(f\"‚ö†Ô∏è {errores} registros fallaron. Guardados en: {archivo_errores}\")\n",
    "\n",
    "print(f\"üéØ Inserci√≥n completada. Total: {insertados} registros. Errores: {errores}\")\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41514e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Validaci√≥n registrada: total_registros\n",
      "üìù Validaci√≥n registrada: suma_subtotal\n",
      "üìù Validaci√≥n registrada: suma_total_neto\n",
      "üìù Validaci√≥n registrada: duplicados\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# FUNCI√ìN PARA REGISTRAR VALIDACIONES\n",
    "# --------------------------------------------\n",
    "def registrar_validacion(nombre_etl, tipo_validacion, resultado, valor_origen, valor_destino, diferencia, mensaje):\n",
    "    try:\n",
    "        insert_val = \"\"\"\n",
    "        INSERT INTO dbo.stage_quality_log (\n",
    "            fecha_ejecucion, nombre_etl, tipo_validacion, resultado,\n",
    "            valor_origen, valor_destino, diferencia, mensaje\n",
    "        )\n",
    "        VALUES (GETDATE(), ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        cursor_sql.execute(insert_val, (\n",
    "            nombre_etl, tipo_validacion, resultado,\n",
    "            valor_origen, valor_destino, diferencia, mensaje\n",
    "        ))\n",
    "        conn_sql.commit()\n",
    "        print(f\"üìù Validaci√≥n registrada: {tipo_validacion}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error registrando validaci√≥n: {tipo_validacion} -> {e}\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# VALIDACI√ìN 1: TOTAL DE REGISTROS\n",
    "# --------------------------------------------\n",
    "try:\n",
    "    cursor_sql.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM stage_ventas_devo\n",
    "        WHERE CAST(fecha_venta AS DATE) BETWEEN ? AND ?\n",
    "    \"\"\", fecha_10_sql, fecha_ayer_sql)\n",
    "    registros_sql = cursor_sql.fetchone()[0]\n",
    "    registros_csv = len(df)\n",
    "\n",
    "    resultado = \"OK\" if registros_sql == registros_csv else \"ERROR\"\n",
    "    diferencia = registros_sql - registros_csv\n",
    "    mensaje = \"Cantidad de registros coincide\" if resultado == \"OK\" else \"Cantidad de registros no coincide\"\n",
    "\n",
    "    registrar_validacion(\n",
    "        nombre_etl=\"ventas_devo\",\n",
    "        tipo_validacion=\"total_registros\",\n",
    "        resultado=resultado,\n",
    "        valor_origen=registros_csv,\n",
    "        valor_destino=registros_sql,\n",
    "        diferencia=diferencia,\n",
    "        mensaje=mensaje\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error validando total registros: {e}\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# VALIDACI√ìN 2: SUMA DE COLUMNAS NUM√âRICAS\n",
    "# --------------------------------------------\n",
    "def validar_suma_columna(columna):\n",
    "    try:\n",
    "        suma_csv = df[columna].sum()\n",
    "        cursor_sql.execute(f\"\"\"\n",
    "            SELECT SUM([{columna}]) FROM stage_ventas_devo\n",
    "            WHERE CAST(fecha_venta AS DATE) BETWEEN ? AND ?\n",
    "        \"\"\", fecha_10_sql, fecha_ayer_sql)\n",
    "        suma_sql = cursor_sql.fetchone()[0] or 0\n",
    "\n",
    "        suma_csv = float(suma_csv)\n",
    "        suma_sql = float(suma_sql)\n",
    "        diferencia = round(suma_sql - suma_csv, 2)\n",
    "        resultado = \"OK\" if abs(diferencia) < 0.01 else \"ERROR\"\n",
    "        mensaje = f\"Suma de {columna} {'coincide' if resultado == 'OK' else 'no coincide'}\"\n",
    "\n",
    "        registrar_validacion(\n",
    "            nombre_etl=\"ventas_devo\",\n",
    "            tipo_validacion=f\"suma_{columna}\",\n",
    "            resultado=resultado,\n",
    "            valor_origen=suma_csv,\n",
    "            valor_destino=suma_sql,\n",
    "            diferencia=diferencia,\n",
    "            mensaje=mensaje\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error validando suma de {columna}: {e}\")\n",
    "\n",
    "# Aplicar validaci√≥n a columnas clave\n",
    "validar_suma_columna(\"subtotal\")\n",
    "validar_suma_columna(\"total_neto\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# VALIDACI√ìN 3: DUPLICADOS\n",
    "# --------------------------------------------\n",
    "try:\n",
    "    query_duplicados = \"\"\"\n",
    "    SELECT folio_venta, sku, num_linea,tipo_transaccion, COUNT(*) as veces\n",
    "    FROM stage_ventas_devo\n",
    "    WHERE CAST(fecha_venta AS DATE) BETWEEN ? AND ?   and  sku <> 'PPPPAGOMF'\n",
    "    GROUP BY folio_venta, sku, num_linea,tipo_transaccion\n",
    "    HAVING COUNT(*) > 1\n",
    "    \"\"\"\n",
    "    cursor_sql.execute(query_duplicados, fecha_10_sql, fecha_ayer_sql)\n",
    "    duplicados = cursor_sql.fetchall()\n",
    "    num_duplicados = len(duplicados)\n",
    "\n",
    "    resultado = \"OK\" if num_duplicados == 0 else \"ERROR\"\n",
    "    mensaje = \"Duplicados por clave\" if resultado == \"ERROR\" else \"Sin duplicados\"\n",
    "\n",
    "    registrar_validacion(\n",
    "        nombre_etl=\"ventas_devo\",\n",
    "        tipo_validacion=\"duplicados\",\n",
    "        resultado=resultado,\n",
    "        valor_origen=num_duplicados,\n",
    "        valor_destino=0,\n",
    "        diferencia=num_duplicados,\n",
    "        mensaje=mensaje\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error validando duplicados: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
